{
  "name": "Claude AI Review Extraction",
  "nodes": [
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "cc095145-86f2-4a04-bbe4-47ec97b65edc",
              "name": "max_records",
              "value": 200,
              "type": "number"
            }
          ]
        },
        "options": {}
      },
      "id": "3c13935e-eac1-4cfc-85fe-449228653ad2",
      "name": "Set → Parameters",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1376,
        208
      ],
      "notes": "max_records: 0 = process all, N = process N records"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "WITH locked_reviews AS (\n  SELECT \n    id, review_id, platform, review_date, rating, reviewer_name, location,\n    review_text, helpful_count, review_url, title, verified_reviewer,\n    verified_customer, local_guide\n  FROM team_pegasus.frontier_reviews\n  WHERE is_processed = false \n    AND (is_processing = false OR is_processing IS NULL)\n  ORDER BY id ASC\n  FOR UPDATE SKIP LOCKED\n  LIMIT CASE WHEN CAST($1 AS INTEGER) > 0 THEN CAST($1 AS INTEGER) ELSE 999999 END\n)\nUPDATE team_pegasus.frontier_reviews\nSET \n  is_processing = true,\n  processing_started_at = NOW()\nFROM locked_reviews\nWHERE frontier_reviews.id = locked_reviews.id\nRETURNING \n  frontier_reviews.id,\n  frontier_reviews.review_id,\n  frontier_reviews.platform,\n  frontier_reviews.review_date,\n  frontier_reviews.rating,\n  frontier_reviews.reviewer_name,\n  frontier_reviews.location,\n  frontier_reviews.review_text,\n  frontier_reviews.helpful_count,\n  frontier_reviews.review_url,\n  frontier_reviews.title,\n  frontier_reviews.verified_reviewer,\n  frontier_reviews.verified_customer,\n  frontier_reviews.local_guide;",
        "options": {
          "queryReplacement": "{{ $json.max_records }}"
        }
      },
      "id": "aba906e8-80ed-4596-aca1-09c4d7a8654c",
      "name": "Postgres → Get Unprocessed Reviews",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        -1184,
        208
      ],
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "8VvvFZVfssWZe1JJ",
          "name": "Postgres account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "hasRecords",
              "leftValue": "={{ $json.length || $input.all().length }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "652cb614-c8f3-4302-95a8-f956daa86e8c",
      "name": "IF → Has Records?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.1,
      "position": [
        -896,
        192
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT review_id, processing_status\nFROM team_pegasus.frontier_reviews_processed\nWHERE review_id = $1\nLIMIT 1;",
        "options": {
          "queryReplacement": "={{ parseInt($('Loop Over Items').first().json.id) || null }}"
        }
      },
      "id": "3b059990-96ba-4ff3-b4ac-463dd50a5cfb",
      "name": "Postgres → Check if Already Processed",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        -448,
        192
      ],
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "8VvvFZVfssWZe1JJ",
          "name": "Postgres account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "mode": "passThrough",
        "options": {}
      },
      "id": "bc3acca0-4743-46b2-9358-ea4a15800301",
      "name": "Merge → After Migration Check",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [
        448,
        176
      ],
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "functionCode": "function removeControlCharacters(text) {\n  if (!text) return '';\n  text = text.replace(/\\0/g, '');\n  text = text.replace(/[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]/g, '');\n  text = text.replace(/[\\u200B-\\u200D\\uFEFF]/g, '');\n  return text;\n}\n\nfunction normalizeCharacters(text) {\n  if (!text) return '';\n  text = text.replace(/[\\u201C\\u201D]/g, '\"');\n  text = text.replace(/[\\u2018\\u2019]/g, \"'\");\n  text = text.replace(/[\\u2013\\u2014]/g, '-');\n  text = text.replace(/\\u2026/g, '...');\n  text = text.replace(/\\u00A0/g, ' ');\n  text = text.replace(/[\\u2022\\u2023\\u2043]/g, '*');\n  text = text.replace(/[\\u0060\\u00B4]/g, \"'\");\n  return text;\n}\n\nfunction sanitizeForJSON(text) {\n  if (!text) return '';\n  text = text.replace(/\\r\\n/g, '\\n');\n  text = text.replace(/\\r/g, '\\n');\n  text = text.replace(/\\n{3,}/g, '\\n\\n');\n  return text;\n}\n\nfunction cleanWhitespace(text) {\n  if (!text) return '';\n  text = text.replace(/[ \\t]+/g, ' ');\n  text = text.replace(/[ \\t]+$/gm, '');\n  text = text.replace(/^[ \\t]+/gm, '');\n  text = text.trim();\n  return text;\n}\n\nfunction cleanText(text) {\n  if (!text) return '';\n  \n  console.log('Original length:', text.length);\n  \n  text = removeControlCharacters(text);\n  text = normalizeCharacters(text);\n  text = sanitizeForJSON(text);\n  text = cleanWhitespace(text);\n  \n  console.log('Cleaned length:', text.length);\n  console.log('Characters removed:', arguments[0].length - text.length);\n  \n  return text;\n}\n\n\nconst review = $('Loop Over Items').first().json;\n\nconst cleanedReviewText = cleanText(review.review_text || '');\nconst cleanedTitle = cleanText(review.title || '');\n\n// Function node to build Claude API request dynamically\n// This avoids duplication by constructing the schema once\n\n// Import the schema (in n8n, you'd store this as a workflow variable or load from file)\nconst extractionSchema = {\n  \"schema_version\": \"1.0\",\n  \"description\": \"Complete attribute schema that Claude LLM can extract from telecom reviews\",\n  \"categories\": {\n    \"summary\": {\n      \"review_summary\": \"string - A concise 20-word summary capturing the essence of the review, including main issue and outcome\"\n    },\n    \"metadata\": {\n      \"review_id\": \"string\",\n      \"source_platform\": \"enum\",\n      \"posted_date\": \"date\",\n      \"review_language\": \"string\",\n      \"character_count\": \"integer\",\n      \"word_count\": \"integer\",\n      \"is_verified_purchase\": \"boolean\"\n    },\n    \"reviewer_profile\": {\n      \"reviewer_type\": \"enum[residential, business, senior, student]\",\n      \"location\": {\n        \"city\": \"string\",\n        \"state\": \"string\",\n        \"region\": \"enum\",\n        \"area_type\": \"enum[urban, suburban, rural]\"\n      },\n      \"customer_tenure\": {\n        \"duration_months\": \"integer\",\n        \"tenure_category\": \"enum[new_customer, established, long_term, very_long_term]\"\n      },\n      \"tech_savviness\": \"enum[low, medium, high, expert]\",\n      \"use_cases\": \"array[string]\",\n      \"criticality_level\": \"enum[casual, moderate, important, mission_critical]\"\n    },\n    \"sentiment_analysis\": {\n      \"overall_sentiment\": \"enum[very_positive, positive, neutral, negative, very_negative, mixed]\",\n      \"sentiment_score\": \"float[-1.0 to 1.0]\",\n      \"sentiment_intensity\": \"enum[mild, moderate, strong, extreme]\",\n      \"emotional_tone\": \"array[string]\",\n      \"urgency_level\": \"enum[low, medium, high, critical]\",\n      \"aspect_based_sentiment\": {\n        \"network_performance\": \"object\",\n        \"pricing_billing\": \"object\",\n        \"customer_service\": \"object\",\n        \"installation_setup\": \"object\",\n        \"equipment_hardware\": \"object\"\n      }\n    },\n    \"classification\": {\n      \"primary_category\": \"string\",\n      \"all_categories\": \"array[string]\",\n      \"subcategories\": \"object\",\n      \"main_categories\": [\n        \"Network Performance\",\n        \"Pricing & Billing\",\n        \"Customer Service\",\n        \"Installation & Setup\",\n        \"Equipment & Hardware\",\n        \"Contracts & Terms\",\n        \"Overall Satisfaction\",\n        \"Coverage & Availability\",\n        \"Competitive Comparison\"\n      ]\n    },\n    \"technical_issues\": {\n      \"problems_identified\": \"array[object]\",\n      \"severity\": \"enum[low, medium, high, critical]\",\n      \"frequency\": \"enum[one_time, rare, occasional, frequent, constant]\",\n      \"resolution_status\": \"enum[unresolved, partially_resolved, resolved, worsening]\"\n    },\n    \"metrics_extracted\": {\n      \"network_metrics\": {\n        \"speed_download\": \"object\",\n        \"speed_upload\": \"object\",\n        \"latency_ping\": \"object\",\n        \"packet_loss\": \"object\"\n      },\n      \"outage_metrics\": {\n        \"outage_count\": \"integer\",\n        \"frequency\": \"string\",\n        \"duration\": \"string\"\n      },\n      \"pricing_metrics\": {\n        \"advertised_price\": \"float\",\n        \"actual_bill_amount\": \"float\",\n        \"price_discrepancy\": \"float\"\n      },\n      \"support_metrics\": {\n        \"contact_attempts\": \"integer\",\n        \"average_wait_time_minutes\": \"integer\",\n        \"resolution_rate\": \"float\"\n      }\n    },\n    \"churn_analysis\": {\n      \"churn_risk\": \"enum[low, medium, high, critical]\",\n      \"churn_probability_score\": \"float[0-1]\",\n      \"churn_indicators\": \"array[string]\",\n      \"switching_intent\": \"object\",\n      \"retention_opportunity\": \"boolean\"\n    },\n    \"competitive_data\": {\n      \"competitors_mentioned\": \"array[string]\",\n      \"previous_provider\": \"string\",\n      \"satisfaction_vs_previous\": \"enum\"\n    },\n    \"business_impact\": {\n      \"nps_indicator\": \"enum[detractor, passive, promoter]\",\n      \"would_recommend\": \"boolean\",\n      \"reputation_risk\": \"enum[low, medium, high, critical]\",\n      \"resolution_urgency\": \"enum[low, medium, high, critical]\"\n    }\n  }\n};\n\n// Build the prompt content\nconst promptContent = `Extract information from this telecom review according to the following schema:\n\n${JSON.stringify(extractionSchema, null, 2)}\n\nReview to analyze:\n${cleanedReviewText}\n\nIMPORTANT: \n1. Generate a 20-word summary that captures the main issue, sentiment, and outcome.\n2. The summary should be concise, clear, and useful for quick review scanning.\n3. Respond with a JSON object containing all extracted fields.\n4. Return only the raw JSON without any markdown formatting.`;\n\n// Build the complete Claude API request\nconst claudeRequest = {\n  model: \"claude-sonnet-4-5-20250929\",\n  max_tokens: 4096,\n  temperature: 0.0,\n  system: \"You are an expert at extracting structured information from telecom customer reviews. Always respond with valid JSON matching the provided schema. Do not include any markdown formatting or code blocks - return only the raw JSON object. Pay special attention to creating concise, informative summaries.\",\n  messages: [\n    {\n      role: \"user\",\n      content: promptContent\n    }\n  ]\n};\n\n// Return the request as output\nreturn [{\n  json: claudeRequest\n}];"
      },
      "id": "d0b286a0-97d9-41ed-82f4-ad5e796e10ed",
      "name": "Function → Prepare Claude Request",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        640,
        176
      ],
      "alwaysOutputData": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "functionCode": "// Enhanced Claude Response Parser with Fallback to Original Data\n// This ensures all fields are populated, using Claude data when available,\n// and falling back to original review data when Claude returns null\n\n// ============================================================================\n// PART 1: Get Original Review Data and Claude Response\n// ============================================================================\n// Enhanced Claude Response Parser with Fallback to Original Data\nconst reviewData = $('Loop Over Items').first().json;\nconst claudeResponse = $json;\n\nconsole.log('Processing Review ID:', reviewData.id);\n\n// Parse Claude Response\nlet extractedText = '';\nlet aiAttributes = {};\n\ntry {\n  if (claudeResponse.content && Array.isArray(claudeResponse.content)) {\n    const textBlock = claudeResponse.content.find(block => block.type === 'text');\n    if (textBlock) {\n      extractedText = textBlock.text;\n    }\n  }\n  \n  try {\n    aiAttributes = JSON.parse(extractedText);\n  } catch (parseError) {\n    const jsonMatch = extractedText.match(/```json\\n([\\s\\S]*?)\\n```/);\n    if (jsonMatch) {\n      aiAttributes = JSON.parse(jsonMatch[1]);\n    }\n  }\n  \n} catch (error) {\n  console.error('Parse error:', error.message);\n  aiAttributes = {};\n}\n\n// Calculate Geographic Metadata\nconst location = reviewData.location || '';\nlet city = null;\nlet state = null;\nlet region = null;\nlet area_type = null;\n\nif (location) {\n  if (location.includes(',')) {\n    const parts = location.split(',').map(s => s.trim());\n    city = parts[0] || null;\n    state = parts[1] || null;\n    \n    const stateRegionMap = {\n      'CA': 'West Coast', 'TX': 'South', 'FL': 'South',\n      'NY': 'Northeast', 'IL': 'Midwest'\n    };\n    region = stateRegionMap[state] || 'Other';\n  } else if (location.toLowerCase().includes('rural')) {\n    city = location;\n    area_type = 'rural';\n  }\n  \n  if (!area_type) {\n    const urbanCities = ['Los Angeles, CA', 'Houston, TX', 'Dallas, TX', 'Austin, TX'];\n    area_type = urbanCities.includes(location) ? 'urban' : 'suburban';\n  }\n}\n\n// Calculate Temporal Metadata\nconst reviewDate = new Date(reviewData.review_date);\nconst isValidDate = reviewData.review_date && !isNaN(reviewDate.getTime());\n\nlet year = null;\nlet month = null;\nlet quarter = null;\nlet weekOfYear = null;\nlet daysAgo = null;\n\nif (isValidDate) {\n  year = reviewDate.getFullYear();\n  month = reviewDate.getMonth() + 1;\n  quarter = 'Q' + Math.ceil(month / 3) + ' ' + year;\n  \n  const d = new Date(Date.UTC(reviewDate.getFullYear(), reviewDate.getMonth(), reviewDate.getDate()));\n  const dayNum = d.getUTCDay() || 7;\n  d.setUTCDate(d.getUTCDate() + 4 - dayNum);\n  const yearStart = new Date(Date.UTC(d.getUTCFullYear(), 0, 1));\n  weekOfYear = Math.ceil((((d - yearStart) / 86400000) + 1) / 7);\n  \n  daysAgo = Math.floor((Date.now() - reviewDate.getTime()) / (1000 * 60 * 60 * 24));\n}\n\n// Extract Fields\nconst review_summary = aiAttributes.summary?.review_summary || null;\nconst sentiment_score = aiAttributes.sentiment_analysis?.sentiment_score || null;\nconst overall_sentiment = aiAttributes.sentiment_analysis?.overall_sentiment || null;\nconst sentiment_intensity = aiAttributes.sentiment_analysis?.sentiment_intensity || null;\nconst urgency_level = aiAttributes.sentiment_analysis?.urgency_level || null;\nconst churn_risk = aiAttributes.churn_analysis?.churn_risk || null;\nconst churn_probability_score = aiAttributes.churn_analysis?.churn_probability_score || null;\nconst retention_opportunity = aiAttributes.churn_analysis?.retention_opportunity || false;\nconst primary_category = aiAttributes.classification?.primary_category || null;\nconst nps_indicator = aiAttributes.business_impact?.nps_indicator || null;\nconst reputation_risk = aiAttributes.business_impact?.reputation_risk || null;\nconst resolution_urgency = aiAttributes.business_impact?.resolution_urgency || null;\nconst reviewer_type = aiAttributes.reviewer_profile?.reviewer_type || 'residential';\nconst customer_tenure_months = aiAttributes.reviewer_profile?.customer_tenure?.duration_months || null;\nconst tenure_category = aiAttributes.reviewer_profile?.customer_tenure?.tenure_category || null;\nconst tech_savviness = aiAttributes.reviewer_profile?.tech_savviness || 'medium';\nconst issue_severity = aiAttributes.technical_issues?.severity || null;\nconst issue_frequency = aiAttributes.technical_issues?.frequency || null;\nconst resolution_status = aiAttributes.technical_issues?.resolution_status || 'unresolved';\n\n// Fallback for would_recommend\nlet would_recommend = aiAttributes.business_impact?.would_recommend;\nif (would_recommend === null || would_recommend === undefined) {\n  would_recommend = reviewData.rating >= 4 ? true : (reviewData.rating <= 2 ? false : null);\n}\n\n// Build Output\nreturn [{\n  json: {\n    review_id: reviewData.id || reviewData.review_id,\n    platform: reviewData.platform,\n    review_date: reviewData.review_date,\n    rating: reviewData.rating,\n    reviewer_name: reviewData.reviewer_name,\n    location: reviewData.location,\n    review_text: reviewData.review_text,\n    review_summary: review_summary,\n    helpful_count: reviewData.helpful_count || 0,\n    review_url: reviewData.review_url,\n    title: reviewData.title || '',\n    verified_reviewer: reviewData.verified_reviewer || false,\n    verified_customer: reviewData.verified_customer || false,\n    local_guide: reviewData.local_guide || false,\n    city: city,\n    state: state,\n    region: region,\n    area_type: area_type,\n    date_parsed: reviewData.review_date,\n    year: year,\n    month: month,\n    quarter: quarter,\n    week_of_year: weekOfYear,\n    days_ago: daysAgo,\n    sentiment_score: sentiment_score,\n    overall_sentiment: overall_sentiment,\n    sentiment_intensity: sentiment_intensity,\n    urgency_level: urgency_level,\n    churn_risk: churn_risk,\n    churn_probability_score: churn_probability_score,\n    retention_opportunity: retention_opportunity,\n    primary_category: primary_category,\n    nps_indicator: nps_indicator,\n    would_recommend: would_recommend,\n    reputation_risk: reputation_risk,\n    resolution_urgency: resolution_urgency,\n    reviewer_type: reviewer_type,\n    customer_tenure_months: customer_tenure_months,\n    tenure_category: tenure_category,\n    tech_savviness: tech_savviness,\n    issue_severity: issue_severity,\n    issue_frequency: issue_frequency,\n    resolution_status: resolution_status,\n    ai_attributes: aiAttributes,\n    processing_status: 'claude_processed',\n    claude_model: claudeResponse.model || 'claude-sonnet-4-5-20250929',\n    tokens_used: claudeResponse.usage ? {\n      input: claudeResponse.usage.input_tokens || 0,\n      output: claudeResponse.usage.output_tokens || 0,\n      total: (claudeResponse.usage.input_tokens || 0) + (claudeResponse.usage.output_tokens || 0)\n    } : null,\n    processing_timestamp: new Date().toISOString()\n  }\n}];\n\n"
      },
      "id": "d5013105-2099-49d8-959a-f843a4b7211a",
      "name": "Function → Parse Claude Response",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        1104,
        144
      ],
      "alwaysOutputData": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- PostgreSQL INSERT with positional parameters ($1, $2, $3...)\n-- Use this in n8n Postgres node\n\nINSERT INTO team_pegasus.frontier_reviews_processed (\n  review_id, platform, review_date, rating, reviewer_name, location,\n  review_text, helpful_count, review_url, title, verified_reviewer,\n  verified_customer, local_guide, city, state, region, area_type,\n  date_parsed, year, month, quarter, week_of_year, days_ago,\n  processing_status, ai_attributes,\n  sentiment_score, overall_sentiment, sentiment_intensity, urgency_level,\n  churn_risk, churn_probability_score, retention_opportunity,\n  primary_category, nps_indicator, would_recommend, reputation_risk,\n  resolution_urgency, reviewer_type, customer_tenure_months,\n  tenure_category, tech_savviness, issue_severity, issue_frequency,\n  resolution_status, last_processed_at, review_summary\n)\nVALUES (\n  $1, $2, $3, $4, $5, $6,\n  $7, $8, $9, $10, $11,\n  $12, $13, $14, $15, $16, $17,\n  $18, $19, $20, $21, $22, $23,\n  $24, $25::jsonb,\n  $26, $27, $28, $29,\n  $30, $31, $32,\n  $33, $34, $35, $36,\n  $37, $38, $39,\n  $40, $41, $42, $43,\n  $44, NOW(),$45\n)\nON CONFLICT (review_id)\nDO UPDATE SET\n  processing_status = EXCLUDED.processing_status,\n  ai_attributes = EXCLUDED.ai_attributes,\n  city = EXCLUDED.city,\n  state = EXCLUDED.state,\n  region = EXCLUDED.region,\n  area_type = EXCLUDED.area_type,\n  date_parsed = EXCLUDED.date_parsed,\n  year = EXCLUDED.year,\n  month = EXCLUDED.month,\n  quarter = EXCLUDED.quarter,\n  week_of_year = EXCLUDED.week_of_year,\n  days_ago = EXCLUDED.days_ago,\n  sentiment_score = EXCLUDED.sentiment_score,\n  overall_sentiment = EXCLUDED.overall_sentiment,\n  sentiment_intensity = EXCLUDED.sentiment_intensity,\n  urgency_level = EXCLUDED.urgency_level,\n  churn_risk = EXCLUDED.churn_risk,\n  churn_probability_score = EXCLUDED.churn_probability_score,\n  retention_opportunity = EXCLUDED.retention_opportunity,\n  primary_category = EXCLUDED.primary_category,\n  nps_indicator = EXCLUDED.nps_indicator,\n  would_recommend = EXCLUDED.would_recommend,\n  reputation_risk = EXCLUDED.reputation_risk,\n  resolution_urgency = EXCLUDED.resolution_urgency,\n  reviewer_type = EXCLUDED.reviewer_type,\n  customer_tenure_months = EXCLUDED.customer_tenure_months,\n  tenure_category = EXCLUDED.tenure_category,\n  tech_savviness = EXCLUDED.tech_savviness,\n  issue_severity = EXCLUDED.issue_severity,\n  issue_frequency = EXCLUDED.issue_frequency,\n  resolution_status = EXCLUDED.resolution_status,\n  last_processed_at = NOW(),\n  review_summary = EXCLUDED.review_summary,\n  updated_at = NOW();\n\n",
        "options": {
          "queryReplacement": "={{ $json.review_id }}, {{ $json.platform }}, {{ $json.review_date }}, {{ $json.rating }}, {{ $json.reviewer_name }}, {{ $json.location }}, {{ $json.review_text }}, {{ $json.helpful_count }}, {{ $json.review_url }}, {{ $json.title }}, {{ $json.verified_reviewer }}, {{ $json.verified_customer }}, {{ $json.local_guide }}, {{ $json.city }}, {{ $json.state }}, {{ $json.region }}, {{ $json.area_type }}, {{ $json.date_parsed }}, {{ $json.year }}, {{ $json.month }}, {{ $json.quarter }}, {{ $json.week_of_year }}, {{ $json.days_ago }}, {{ $json.processing_status }}, {{ JSON.stringify($json.ai_attributes) }}, {{ $json.sentiment_score }}, {{ $json.overall_sentiment }}, {{ $json.sentiment_intensity }}, {{ $json.urgency_level }}, {{ $json.churn_risk }}, {{ $json.churn_probability_score }}, {{ $json.retention_opportunity }}, {{ $json.primary_category }}, {{ $json.nps_indicator }}, {{ $json.would_recommend }}, {{ $json.reputation_risk }}, {{ $json.resolution_urgency }}, {{ $json.reviewer_type }}, {{ $json.customer_tenure_months }}, {{ $json.tenure_category }}, {{ $json.tech_savviness }}, {{ $json.issue_severity }}, {{ $json.issue_frequency }}, {{ $json.resolution_status }}, {{ $json.review_summary }}"
        }
      },
      "id": "4d72dc30-1db9-4c0b-93b5-4190fde43832",
      "name": "Postgres → Insert/Update (Claude Processed)",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        1328,
        128
      ],
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "8VvvFZVfssWZe1JJ",
          "name": "Postgres account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "functionCode": "// Prepare text for GTE embedding\n// At this point, $json contains the processed Claude response data\n//const processedData = $json;\nconst processedData = $('Loop Over Items').first().json;\n\n// Get the review text and title\nconst textToEmbed = [processedData.title, processedData.review_text]\n  .filter(Boolean)\n  .join(' ')\n  .trim();\n\n// Validate we have text to embed\nif (!textToEmbed || textToEmbed.length === 0) {\n  throw new Error('No text available for embedding');\n}\n\nconsole.log('Preparing embedding for review:', processedData.review_id);\nconsole.log('Text length:', textToEmbed.length);\n\nreturn [{\n  json: {\n    review_id: processedData.review_id,\n    text_to_embed: textToEmbed,\n    // Keep other data to pass along\n    platform: processedData.platform\n  }\n}];"
      },
      "id": "4ae1fdeb-8cc6-4cba-8c73-8898afe22500",
      "name": "Function → Prepare GTE Embedding",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        672,
        480
      ],
      "alwaysOutputData": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://dbc-4a93b454-f17b.cloud.databricks.com/serving-endpoints/databricks-gte-large-en/invocations",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ input: [$json.text_to_embed] }) }}",
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          },
          "timeout": 300000
        }
      },
      "id": "6588653f-17f1-4cab-a19a-ac4f8a7859c6",
      "name": "HTTP → GTE Embedding API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        896,
        464
      ],
      "alwaysOutputData": true,
      "retryOnFail": true,
      "credentials": {
        "httpBearerAuth": {
          "id": "JoKENnnyWMvFDz5R",
          "name": "Bearer Auth account"
        }
      },
      "onError": "continueErrorOutput",
      "notes": "Call GTE embedding API. Update URL and auth based on your GTE service."
    },
    {
      "parameters": {
        "functionCode": "// Parse Databricks GTE Embedding Response with Null Handling\n// Handles cases where input is null, undefined, or malformed\n\n// ============================================================================\n// PART 1: Validate Inputs\n// ============================================================================\n\n// Get embedding response\nconst embeddingResponse = $json;\n\n// Get review data from the loop\nconst reviewData = $('Loop Over Items').first().json;\n\n// Validate embedding response exists\nif (!embeddingResponse || typeof embeddingResponse !== 'object') {\n  console.error('❌ Invalid embedding response:', embeddingResponse);\n  throw new Error('GTE API returned null or invalid response');\n}\n\n// Get review ID from loop data\nlet reviewId = reviewData.review_id || reviewData.id;\nlet platform = reviewData.platform;\n\nconsole.log('Loop data keys:', Object.keys(reviewData));\nconsole.log('review_id:', reviewId);\nconsole.log('id:', reviewData.id);\nconsole.log('platform:', platform);\n\n// Validate review ID\nif (!reviewId) {\n  console.error('❌ Review ID is missing');\n  console.error('Available keys in loop:', Object.keys(reviewData));\n  console.error('reviewData.id:', reviewData.id);\n  console.error('reviewData.review_id:', reviewData.review_id);\n  throw new Error('Invalid review ID - not found in loop data');\n}\n\nconsole.log('✓ Processing embedding for review:', reviewId);\n\n// ============================================================================\n// PART 2: Extract Embedding with Null Checks\n// ============================================================================\n\nlet embedding = null;\nlet embeddingString = null;\n\ntry {\n  // OpenAI-compatible format: { \"data\": [{ \"embedding\": [...] }] }\n  if (embeddingResponse.data && Array.isArray(embeddingResponse.data) && embeddingResponse.data.length > 0) {\n    const firstData = embeddingResponse.data[0];\n    if (firstData && firstData.embedding) {\n      embedding = firstData.embedding;\n      console.log('✓ Found embedding in OpenAI format (data array)');\n    }\n  }\n  \n  // Databricks format: { \"predictions\": [[...]] }\n  if (!embedding && embeddingResponse.predictions && Array.isArray(embeddingResponse.predictions) && embeddingResponse.predictions.length > 0) {\n    const firstPrediction = embeddingResponse.predictions[0];\n    if (firstPrediction) {\n      embedding = firstPrediction;\n      console.log('✓ Found embedding in Databricks format (predictions)');\n    }\n  }\n  \n  // Direct array format\n  if (!embedding && Array.isArray(embeddingResponse) && embeddingResponse.length > 0) {\n    embedding = embeddingResponse[0];\n    console.log('✓ Found embedding in direct array');\n  }\n  \n  // Object with embedding key\n  if (!embedding && embeddingResponse.embedding) {\n    embedding = embeddingResponse.embedding;\n    console.log('✓ Found embedding in object');\n  }\n  \n  // Check if we found an embedding\n  if (!embedding) {\n    console.error('❌ No embedding found in response');\n    console.error('Response structure:', JSON.stringify(embeddingResponse).substring(0, 300));\n    throw new Error('Could not extract embedding from response. Response keys: ' + Object.keys(embeddingResponse).join(', '));\n  }\n  \n  // Validate embedding is an array\n  if (!Array.isArray(embedding)) {\n    console.error('❌ Embedding is not an array. Type:', typeof embedding);\n    throw new Error('Embedding is not a valid array. Got: ' + typeof embedding);\n  }\n  \n  // Validate embedding has values\n  if (embedding.length === 0) {\n    console.error('❌ Embedding array is empty');\n    throw new Error('Embedding array is empty');\n  }\n  \n  // Validate embedding values are numbers\n  const hasInvalidValues = embedding.some(val => typeof val !== 'number' || isNaN(val));\n  if (hasInvalidValues) {\n    console.error('❌ Embedding contains non-numeric values');\n    throw new Error('Embedding contains invalid (non-numeric) values');\n  }\n  \n  // Convert to PostgreSQL vector format: '[0.1,0.2,0.3,...]'\n  embeddingString = '[' + embedding.join(',') + ']';\n  \n  console.log('✓ Embedding dimension:', embedding.length);\n  console.log('✓ First 5 values:', embedding.slice(0, 5));\n  console.log('✓ Last 5 values:', embedding.slice(-5));\n  \n  // Check for expected dimensions (GTE-large should be 1024)\n  if (embedding.length !== 1024 && embedding.length !== 768) {\n    console.warn('⚠️ Unexpected embedding dimension:', embedding.length);\n    console.warn('Expected: 1024 (GTE-large) or 768 (GTE-base)');\n  }\n  \n} catch (error) {\n  console.error('❌ Failed to parse embedding:', error.message);\n  console.error('Response type:', typeof embeddingResponse);\n  console.error('Response keys:', embeddingResponse ? Object.keys(embeddingResponse).join(', ') : 'null');\n  \n  // Re-throw with more context\n  throw new Error('Embedding parse error: ' + error.message);\n}\n\n// ============================================================================\n// PART 3: Build and Return Output\n// ============================================================================\n\n// Get model name safely\nconst modelName = embeddingResponse.model || \n                 embeddingResponse.metadata?.model || \n                 'databricks-gte-large-en';\n\nconsole.log('✓ Model:', modelName);\nconsole.log('✓ Final review_id for output:', reviewId);\n\n// Return complete data with embedding\nreturn [{\n  json: {\n    // Review identification from loop\n    review_id: reviewId,\n    \n    // Add embedding data\n    gte_embedding: embeddingString,\n    embedding_array: embedding,\n    embedding_dimension: embedding.length,\n    embedding_model: modelName,\n    embedding_created_at: new Date().toISOString(),\n    \n    // Token usage (if available)\n    embedding_tokens: embeddingResponse.usage?.total_tokens || \n                     embeddingResponse.usage?.prompt_tokens || \n                     null,\n    \n    // Update processing status\n    processing_status: 'embedding_completed'\n  }\n}];"
      },
      "id": "e8ec9662-e231-495e-b68a-b494d1182106",
      "name": "Function → Parse GTE Embedding",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        1136,
        448
      ],
      "alwaysOutputData": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE team_pegasus.frontier_reviews_processed\nSET\n  gte_embedding = $1::vector,\n  embedding_model = 'gte-base',\n  embedding_created_at = NOW(),\n  processing_status = 'vector_processed',\n  last_processed_at = NOW(),\n  updated_at = NOW()\nWHERE review_id = $2;",
        "options": {
          "queryReplacement": "{{ $json.gte_embedding }},{{ $json.review_id }}"
        }
      },
      "id": "03d78d3e-944c-47bd-b979-a37d419ef742",
      "name": "Postgres → Update Embedding",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        1344,
        432
      ],
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "8VvvFZVfssWZe1JJ",
          "name": "Postgres account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE team_pegasus.frontier_reviews_processed\nSET\n  processing_status = 'completed',\n  last_processed_at = NOW(),\n  updated_at = NOW()\nWHERE review_id = $1;\n\nUPDATE team_pegasus.frontier_reviews\nSET \n  is_processed = true,      -- Mark as done\n  is_processing = false,    -- Unlock the record\n  processed_at = NOW(),\n  updated_at = NOW()\nWHERE review_id = $1;",
        "options": {
          "queryReplacement": "={{ $('Loop Over Items').first().json.review_id }}"
        }
      },
      "id": "918d451b-381c-49e6-8ca8-830b3f6440cc",
      "name": "Postgres → Mark Completed",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        1648,
        416
      ],
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "8VvvFZVfssWZe1JJ",
          "name": "Postgres account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "functionCode": "// ============================================================================\n// UNIVERSAL ERROR HANDLER - Works with any workflow structure\n// ============================================================================\n\nconsole.log('=== ERROR HANDLER STARTED ===');\n\n// Initialize default values\nlet reviewData = {};\nlet reviewId = 'unknown';\nlet platform = 'unknown';\nlet reviewTextPreview = null;\n\n// ============================================================================\n// STEP 1: Try to get review data from various sources\n// ============================================================================\n\ntry {\n  // Method 1: Try to get from $input (most common)\n  const inputItems = $input.all();\n  console.log('Input items count:', inputItems.length);\n  \n  if (inputItems && inputItems.length > 0) {\n    // Loop through input items to find review data\n    for (const item of inputItems) {\n      if (item.json) {\n        // Check if this item has review data\n        if (item.json.review_id || item.json.id) {\n          reviewData = item.json;\n          reviewId = item.json.review_id || item.json.id || 'unknown';\n          platform = item.json.platform || 'unknown';\n          reviewTextPreview = item.json.review_text ? item.json.review_text.substring(0, 100) + '...' : null;\n          console.log('Found review data in input:', reviewId);\n          break;\n        }\n      }\n    }\n  }\n  \n  // Method 2: Try to get from $json directly\n  if (reviewId === 'unknown' && $json) {\n    if ($json.review_id || $json.id) {\n      reviewData = $json;\n      reviewId = $json.review_id || $json.id || 'unknown';\n      platform = $json.platform || 'unknown';\n      reviewTextPreview = $json.review_text ? $json.review_text.substring(0, 100) + '...' : null;\n      console.log('Found review data in $json:', reviewId);\n    }\n  }\n  \n  // Method 3: Try to get from item(0)\n  if (reviewId === 'unknown') {\n    const firstItem = $item(0);\n    if (firstItem && firstItem.json) {\n      if (firstItem.json.review_id || firstItem.json.id) {\n        reviewData = firstItem.json;\n        reviewId = firstItem.json.review_id || firstItem.json.id || 'unknown';\n        platform = firstItem.json.platform || 'unknown';\n        reviewTextPreview = firstItem.json.review_text ? firstItem.json.review_text.substring(0, 100) + '...' : null;\n        console.log('Found review data in item(0):', reviewId);\n      }\n    }\n  }\n  \n} catch (e) {\n  console.log('Could not retrieve review data:', e.message);\n}\n\nconsole.log('Final reviewId:', reviewId);\nconsole.log('Final platform:', platform);\n\n// ============================================================================\n// STEP 2: Get error information\n// ============================================================================\n\nlet errorNode = 'unknown node';\nlet errorType = 'UnknownError';\nlet errorMessage = 'Unknown error occurred';\nlet errorStack = null;\nlet errorDetails = {};\n\ntry {\n  // Get the error object from various possible locations\n  let errorObj = null;\n  \n  // Try $json.error\n  if ($json && $json.error) {\n    errorObj = $json.error;\n    console.log('Found error in $json.error');\n  }\n  \n  // Try input item error\n  if (!errorObj) {\n    const inputItems = $input.all();\n    for (const item of inputItems) {\n      if (item.json && item.json.error) {\n        errorObj = item.json.error;\n        console.log('Found error in input item');\n        break;\n      }\n    }\n  }\n  \n  // Try $node context\n  if (!errorObj && $node) {\n    errorNode = $node.name || 'unknown node';\n    console.log('Using node name:', errorNode);\n  }\n  \n  // Parse error object if found\n  if (errorObj) {\n    errorNode = errorObj.node || errorObj.name || errorNode;\n    errorType = errorObj.type || errorObj.name || errorType;\n    errorMessage = errorObj.message || errorObj.description || errorMessage;\n    errorStack = errorObj.stack || null;\n    \n    console.log('Parsed error - Node:', errorNode, 'Type:', errorType);\n  } else {\n    // If no error object found, check if we have raw error data\n    if ($json) {\n      errorMessage = $json.message || $json.error_message || errorMessage;\n      errorType = $json.type || $json.error_type || errorType;\n      errorNode = $json.node || errorNode;\n      console.log('Using raw error data from $json');\n    }\n  }\n  \n  // Build error details\n  errorDetails = {\n    node: errorNode,\n    type: errorType,\n    message: errorMessage,\n    timestamp: new Date().toISOString(),\n    review_id: reviewId,\n    execution_id: $execution ? $execution.id : 'unknown',\n    workflow_id: $workflow ? $workflow.id : 'unknown'\n  };\n  \n  // Add additional context if available\n  if (errorObj) {\n    if (errorObj.httpCode) errorDetails.httpCode = errorObj.httpCode;\n    if (errorObj.statusCode) errorDetails.statusCode = errorObj.statusCode;\n    if (errorObj.cause) errorDetails.cause = errorObj.cause;\n    if (errorObj.description) errorDetails.description = errorObj.description;\n  }\n  \n} catch (parseError) {\n  console.error('Error parsing error information:', parseError.message);\n  errorDetails = {\n    node: 'error_handler',\n    type: 'ErrorParsingError',\n    message: 'Could not parse error information',\n    parse_error: parseError.message,\n    timestamp: new Date().toISOString(),\n    execution_id: $execution ? $execution.id : 'unknown',\n    workflow_id: $workflow ? $workflow.id : 'unknown'\n  };\n}\n\n// ============================================================================\n// STEP 3: Log everything for debugging\n// ============================================================================\n\nconsole.log('=== ERROR CAPTURED ===');\nconsole.log('Review ID:', reviewId);\nconsole.log('Platform:', platform);\nconsole.log('Error Node:', errorNode);\nconsole.log('Error Type:', errorType);\nconsole.log('Error Message:', errorMessage);\nconsole.log('Execution ID:', $execution ? $execution.id : 'unknown');\nconsole.log('Full Details:', JSON.stringify(errorDetails, null, 2));\n\n// ============================================================================\n// STEP 4: Return structured error data\n// ============================================================================\n\nreturn [{\n  json: {\n    // Review identification\n    review_id: reviewId,\n    platform: platform,\n    review_text_preview: reviewTextPreview,\n    \n    // Error information\n    error_node: errorNode,\n    error_type: errorType,\n    error_message: errorMessage,\n    error_stack: errorStack,\n    error_details: JSON.stringify(errorDetails),\n    \n    // Metadata\n    processing_status: 'errored',\n    error_timestamp: new Date().toISOString(),\n    execution_id: $execution ? $execution.id : 'unknown',\n    workflow_id: $workflow ? $workflow.id : 'unknown',\n    \n    // Original review data (for retry)\n    original_review_data: reviewData\n  }\n}];"
      },
      "id": "1111cdee-b76a-4d5b-83cc-ce7543d52150",
      "name": "Function → Error Handler",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -544,
        960
      ],
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO team_pegasus.frontier_reviews_errors (\n  review_id,\n  platform,\n  error_node,\n  error_type,\n  error_message,\n  error_stack,\n  error_details,\n  processing_status,\n  error_timestamp,\n  execution_id,\n  workflow_id,\n  review_text_preview,\n  original_review_data\n)\nVALUES (\n  $1,  -- review_id\n  $2,  -- platform\n  $3,  -- error_node\n  $4,  -- error_type\n  $5,  -- error_message\n  $6,  -- error_stack\n  $7,  -- error_details (JSONB)\n  $8,  -- processing_status\n  $9,  -- error_timestamp\n  $10, -- execution_id\n  $11, -- workflow_id\n  $12, -- review_text_preview\n  $13::jsonb  -- original_review_data (JSONB)\n)\nON CONFLICT (review_id, error_timestamp) DO UPDATE SET\n  error_details = EXCLUDED.error_details,\n  error_message = EXCLUDED.error_message,\n  updated_at = NOW();\n\n-- Reset is_processing so the review can be retried\n--UPDATE team_pegasus.frontier_reviews\n--SET \n--  is_processing = false,\n -- processing_started_at = NULL\n--WHERE review_id = $1;",
        "options": {
          "queryReplacement": "={{ $json.review_id }}, {{ $json.platform }}, {{ $json.error_node }}, {{ $json.error_type }}, {{ $json.error_message }}, {{ $json.error_stack }}, {{ $json.error_details }}, {{ $json.processing_status }}, {{ $json.error_timestamp }}, {{ $json.execution_id }}, {{ $json.workflow_id }}, {{ $json.review_text_preview }}, {{ JSON.stringify($json.original_review_data) }}"
        }
      },
      "id": "94dcba4d-13c6-4fce-8347-f9e379712cc6",
      "name": "Postgres → Mark Errored",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        -288,
        944
      ],
      "credentials": {
        "postgres": {
          "id": "8VvvFZVfssWZe1JJ",
          "name": "Postgres account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {},
      "id": "17483159-322a-4718-ad91-0a9c2c4a85ed",
      "name": "Done (no records)",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        -880,
        -112
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "notInProcessed",
              "leftValue": "={{ $json.length || 0 }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "eq"
              }
            },
            {
              "id": "7f1ef078-7ff2-4143-a59d-94238914ace3",
              "leftValue": "={{ $json.length || $input.all().length }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "9699020e-58f5-43c2-9d29-495cbb5daa80",
      "name": "IF → Has Metadata?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.1,
      "position": [
        -176,
        176
      ],
      "alwaysOutputData": true,
      "notes": "If record not in processed table, migrate it first"
    },
    {
      "parameters": {
        "functionCode": "// Calculate metadata for migration (same logic as Python script)\n\nconst review = $('Loop Over Items').first().json;\n\nconsole.log(review)\n\n// Calculate geographic metadata from location\nconst location = review.location || '';\nlet city = null, state = null, region = null, area_type = null;\n\nif (location.includes(',')) {\n  const parts = location.split(',').map(s => s.trim());\n  city = parts[0] || null;\n  state = parts[1] || null;\n  \n  // Determine region from state\n  if (state === 'CA') region = 'West Coast';\n  else if (state === 'TX') region = 'South';\n  else region = 'Other';\n} else if (location.startsWith('Rural')) {\n  city = location;\n  area_type = 'rural';\n}\n\n// Determine area type\nif (!area_type) {\n  const urbanCities = ['Los Angeles, CA', 'San Diego, CA', 'San Jose, CA', 'San Francisco, CA', 'Fresno, CA', 'Sacramento, CA', 'Long Beach, CA', 'Oakland, CA', 'Houston, TX', 'Dallas, TX', 'San Antonio, TX', 'Austin, TX', 'Fort Worth, TX', 'El Paso, TX', 'Arlington, TX', 'Corpus Christi, TX'];\n  if (urbanCities.includes(location)) {\n    area_type = 'urban';\n  } else {\n    area_type = 'suburban';\n  }\n}\n\n// Calculate temporal metadata from review_date\nconst reviewDate = new Date(review.review_date);\nconst year = reviewDate.getFullYear();\nconst month = reviewDate.getMonth() + 1;\nconst quarter = 'Q' + Math.ceil(month / 3) + ' ' + year;\n\n// Calculate ISO week number\nfunction getWeekNumber(date) {\n  const d = new Date(Date.UTC(date.getFullYear(), date.getMonth(), date.getDate()));\n  const dayNum = d.getUTCDay() || 7;\n  d.setUTCDate(d.getUTCDate() + 4 - dayNum);\n  const yearStart = new Date(Date.UTC(d.getUTCFullYear(), 0, 1));\n  return Math.ceil((((d - yearStart) / 86400000) + 1) / 7);\n}\nconst weekOfYear = getWeekNumber(reviewDate);\nconst daysAgo = Math.floor((new Date() - reviewDate) / (1000 * 60 * 60 * 24));\n\nreturn [{\n  json: {\n    review_id: review.review_id || review.id,\n    platform: review.platform,\n    review_date: review.review_date,\n    rating: review.rating,\n    reviewer_name: review.reviewer_name,\n    location: review.location,\n    review_text: review.review_text,\n    helpful_count: review.helpful_count || 0,\n    review_url: review.review_url,\n    title: review.title,\n    verified_reviewer: review.verified_reviewer,\n    verified_customer: review.verified_customer,\n    local_guide: review.local_guide,\n    // Geographic metadata\n    city: city,\n    state: state,\n    region: region,\n    area_type: area_type,\n    // Temporal metadata\n    date_parsed: review.review_date,\n    year: year,\n    month: month,\n    quarter: quarter,\n    week_of_year: weekOfYear,\n    days_ago: daysAgo,\n    // Processing status\n    processing_status: 'pending',\n    // Empty AI attributes (will be populated by Claude)\n    ai_attributes: {}\n  }\n}];"
      },
      "id": "cf29e1be-7a88-466a-8573-1be8391ba806",
      "name": "Function → Calculate Metadata",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        0,
        432
      ],
      "alwaysOutputData": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO team_pegasus.frontier_reviews_processed (\n  review_id, platform, review_date, rating, reviewer_name, location,\n  review_text, helpful_count, review_url, title, verified_reviewer,\n  verified_customer, local_guide,\n  city, state, region, area_type,\n  date_parsed, year, month, quarter, week_of_year, days_ago,\n  processing_status, ai_attributes\n)\nVALUES (\n  $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19,$20, $21, $22, $23, $24, $25\n)\nON CONFLICT (review_id) DO NOTHING;",
        "options": {
          "queryReplacement": "{{ $json.review_id }}, {{ $json.platform }}, {{ $json.review_date }}, {{ $json.rating }}, {{ $json.reviewer_name }}, {{ $json.location }},   {{ $json.review_text }}, {{ $json.helpful_count }}, {{ $json.review_url }}, {{ $json.title }}, {{ $json.verified_reviewer }},   {{ $json.verified_customer }}, {{ $json.local_guide }},   {{ $json.city }}, {{ $json.state }}, {{ $json.region }}, {{ $json.area_type }},   {{ $json.date_parsed }}, {{ $json.year }}, {{ $json.month }}, {{ $json.quarter }}, {{ $json.week_of_year }}, {{ $json.days_ago }},   {{ $json.processing_status }}, {{ $json.ai_attributes }}"
        }
      },
      "id": "a6ea75e7-83dc-42bd-8470-c21613a55178",
      "name": "Postgres → Insert Record to Processed Table",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        272,
        416
      ],
      "credentials": {
        "postgres": {
          "id": "8VvvFZVfssWZe1JJ",
          "name": "Postgres account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            },
            {
              "name": "content-type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json) }}",
        "options": {
          "timeout": 300000
        }
      },
      "id": "df637564-65c1-41ba-8961-562fd5deaf5e",
      "name": "Claude AI Extraction",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        864,
        160
      ],
      "alwaysOutputData": true,
      "retryOnFail": true,
      "credentials": {
        "httpHeaderAuth": {
          "id": "Yrzx98DrPmwlWJs5",
          "name": "Header Auth account"
        },
        "anthropicApi": {
          "id": "Nkgn1ozqdDtVKFsC",
          "name": "Anthropic account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "path": "74ec6413-a383-4c81-a875-0c1a943724e0",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        -1584,
        336
      ],
      "id": "506a7c13-0306-4cb1-bf96-3b72cd9ec82f",
      "name": "Webhook",
      "webhookId": "74ec6413-a383-4c81-a875-0c1a943724e0",
      "executeOnce": false
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        -656,
        176
      ],
      "id": "57823ac1-d77e-4c10-90c3-27abdb454388",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        -1584,
        160
      ],
      "id": "95f3ff48-1137-4547-ba17-ea5824278dea",
      "name": "Hourly Trigger"
    }
  ],
  "pinData": {},
  "connections": {
    "Set → Parameters": {
      "main": [
        [
          {
            "node": "Postgres → Get Unprocessed Reviews",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres → Get Unprocessed Reviews": {
      "main": [
        [
          {
            "node": "IF → Has Records?",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF → Has Records?": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Done (no records)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres → Check if Already Processed": {
      "main": [
        [
          {
            "node": "IF → Has Metadata?",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge → After Migration Check": {
      "main": [
        [
          {
            "node": "Function → Prepare Claude Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Function → Prepare Claude Request": {
      "main": [
        [
          {
            "node": "Claude AI Extraction",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Function → Parse Claude Response": {
      "main": [
        [
          {
            "node": "Postgres → Insert/Update (Claude Processed)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres → Insert/Update (Claude Processed)": {
      "main": [
        [
          {
            "node": "Function → Prepare GTE Embedding",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Function → Prepare GTE Embedding": {
      "main": [
        [
          {
            "node": "HTTP → GTE Embedding API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP → GTE Embedding API": {
      "main": [
        [
          {
            "node": "Function → Parse GTE Embedding",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Function → Parse GTE Embedding": {
      "main": [
        [
          {
            "node": "Postgres → Update Embedding",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres → Update Embedding": {
      "main": [
        [
          {
            "node": "Postgres → Mark Completed",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres → Mark Completed": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Function → Error Handler": {
      "main": [
        [
          {
            "node": "Postgres → Mark Errored",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF → Has Metadata?": {
      "main": [
        [
          {
            "node": "Merge → After Migration Check",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Calculate Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Function → Calculate Metadata": {
      "main": [
        [
          {
            "node": "Postgres → Insert Record to Processed Table",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres → Insert Record to Processed Table": {
      "main": [
        [
          {
            "node": "Merge → After Migration Check",
            "type": "main",
            "index": 1
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude AI Extraction": {
      "main": [
        [
          {
            "node": "Function → Parse Claude Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Function → Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Set → Parameters",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [],
        [
          {
            "node": "Postgres → Check if Already Processed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Hourly Trigger": {
      "main": [
        [
          {
            "node": "Set → Parameters",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false
  },
  "versionId": "e3cca36c-9b3b-451c-b732-8068916d5505",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "8bbd75db5d93ed253da161a3f9a43848c8f523ad03d972422905e3095636f77f"
  },
  "id": "ir0rGtxRMvxsFWkw",
  "tags": []
}